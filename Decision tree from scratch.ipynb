{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dataset\n",
    "# Format: each row is a data point\n",
    "# The last column is the label \n",
    "# The first two columns are features\n",
    "\n",
    "trainingData = [['Green',3,'Mango'],\n",
    "               ['Yellow',3,'Mango'],\n",
    "               ['Red',1,'Grape'],\n",
    "               ['Red',1,'Grape'],\n",
    "               ['Yellow',3,'Lemon']]\n",
    "#column Labels\n",
    "header = ['color','diameter','label']\n",
    "\n",
    "\n",
    "def unique_vals(rows,col):\n",
    "    \"\"\"find the unique values in the columns in the dataset\"\"\"\n",
    "    return set([row[col]for row in rows])\n",
    "####### \n",
    "#unique_vals(trainingData, 0)\n",
    "#unique_vals(trainingData, 1)\n",
    "\n",
    "def class_count(rows):\n",
    "    \"\"\"counts the number of each type of example in a dataset\"\"\"\n",
    "    counts = {} # a dictionary of label -count\n",
    "    for row in rows:\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts\n",
    "\n",
    "# class_counts(trainingData)\n",
    "\n",
    "#isinstance is a function used to check whether a particular value is of a particular type returns true or false\n",
    "def is_numeric(value):\n",
    "    \"\"\"Tests if a value is numeric\"\"\"\n",
    "    return isinstance(value,int) or isinstance(value,float)\n",
    "#is_numeric(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "set([1,2,2,3,4,5,5,5,6,7,7,7,8,9])\n",
    "\n",
    "things = (1,3,4,5,6,7,78,8,8,8,8)\n",
    "for i in range(20):\n",
    "    if i not in things:\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-c5b26f119585>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-c5b26f119585>\"\u001b[1;36m, line \u001b[1;32m29\u001b[0m\n\u001b[1;33m    true_rows , false_rows = [],[]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class Question:\n",
    "    \"\"\"used to partition a dataset.\n",
    "    This class just records a 'column number '(e.g, 0 for color) and a column value(e.g,green).\n",
    "    the 'match method' is used to compare the feature value in an example to the feature value \n",
    "    stored in the question. See the demo below\"\"\"\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "        \n",
    "    def match (self,example):\n",
    "        #compare the feature value is in an example to the feature value in question\n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else: \n",
    "            return val == self.value\n",
    "    def __repr__(self):\n",
    "        #this is just a helper method to print question in readable format\n",
    "        condition = '=='\n",
    "        if is_numeric(self.value):\n",
    "            return \"Is %s %s %s?\" % (\n",
    "            header[self.column],condition,str(self.value))\n",
    "        \n",
    "def partition(rows, question):\n",
    "    \"\"\"partitions a dataset \n",
    "    \n",
    "    For each row in the dataset, check if it matches the question. If so add it to 'true rows',\n",
    "    otherwise add it to 'false row'\"\"\"\n",
    "        true_rows , false_rows = [],[]\n",
    "        for row in rows:\n",
    "            if question.match(row):\n",
    "                true_rows.append(row)\n",
    "            else:\n",
    "                false_rows.append(row)\n",
    "        return true_rows, false_rows\n",
    "# Demo    \n",
    "# Let's partition the training data based on whether rows are red.\n",
    "# true_rows, false_rows = partition(training_data,Question(0,'Red'))\n",
    "#this will contain all the red rows(true_rows)\n",
    "# false_rows will contain everything else\n",
    "\n",
    "\n",
    "def gini(rows):\n",
    "    \"\"\"Calculates the Gini index(level of impurity in each row)\"\"\"\n",
    "    \n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl]/float(len(rows))\n",
    "        impurity -= prob_of_lbl**2\n",
    "        return impurity\n",
    "    \n",
    "# demo:\n",
    "# let's look at the same example to understand how gini impurity works\n",
    "        \n",
    "    \n",
    "def info_gain(left,right, current_uncertainty):\n",
    "    \"\"\"information Gain.\n",
    "    \n",
    "    The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nods\n",
    "    \"\"\"\n",
    "    p = float(len(left))/(len(left)) + len(right)\n",
    "    \n",
    "    return current_uncertainty - p*gini(left) - (1-p)*gini(right)\n",
    "\n",
    "####\n",
    "# demo \n",
    "# Calculate the uncertainty of our training data\n",
    "# current_uncertainty - gini(training_data)\n",
    "#\n",
    "# How much information do we gain by partioning on Green?\n",
    "# true_rows,false_rows = partition(training_data,Question(0,'Green'))\n",
    "# info_gain(true_rows, false_rows, current_uncertainty)\n",
    "#\n",
    "#What if we partitioned red instead\n",
    "# true_rows, false_rows = partition(training_data,Question(0,'Red'))\n",
    "# info_gain(true_rows, false_rows, current_uncertainty)\n",
    "\n",
    "def find_best_split(rows):\n",
    "    \"\"\"Finds the best question to ask by iterating over every feature/value\n",
    "    and calculating the information gain\"\"\"\n",
    "    \n",
    "    best_gain = 0 # to keep track of information gain\n",
    "    best_question = None # keep tracks of the feature /value that produced it\n",
    "    current_uncertainty = gini(rows)\n",
    "    n_features = len(row[0])-1 # number of columns\n",
    "    \n",
    "    for col in range(n_features): #for each feature\n",
    "        values = set([row[col]] for row in rows) # unique values in the column\n",
    "        \n",
    "        for val in values: # for each value\n",
    "            \n",
    "            question = Question(col, val)\n",
    "            \n",
    "            #try splitting the dataset\n",
    "            true_rows, false_rows = partition(rows,question)\n",
    "            \n",
    "            #skip the split if it doesnt divide the dataset\n",
    "            \n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            # calculate the information gain from this split\n",
    "            gain = info_gain(true_rows,false_rows,current_uncertainty)\n",
    "            \n",
    "            # you actually can use '>' instead of '>=' here\n",
    "            # but i wan the tree to look a certain way for the dataset\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "            return best_gain, best_question\n",
    "\n",
    "    class Leaf:\n",
    "        \"\"\"A leaf node classifies the data.\n",
    "        \n",
    "        This holds a dictionarty of class (e.g,\"mangeo\")-> number of times\n",
    "        it appears in the rows from the training data that reach this leaf.\n",
    "        \"\"\"\n",
    "        def __init__(self, rows):\n",
    "            self.predictions = class_counts(rows)\n",
    "            \n",
    "        \n",
    "    class Decision_Node:\n",
    "        \"\"\"A decision node asks a question.\n",
    "        This holds a reference to the question and to the two child nodes.\n",
    "        \"\"\"\n",
    "        \n",
    "        def __init__(self,\n",
    "                    question,\n",
    "                    true_branch,\n",
    "                    false_branch):\n",
    "            self.question = question\n",
    "            self.true_branch = true_branch\n",
    "            self.false_branch = false_branch\n",
    "        def build_tree(rows):\n",
    "            \"\"\"Builds the tree\"\"\"\n",
    "            # try partitioning the dataset on each of the unique attribute,\n",
    "            # calclulte the information gain and return the question that produces the highest information gain\n",
    "            gain, question = find_best_split(rows)\n",
    "            \n",
    "            # Base case: no further info gain\n",
    "            # since we can ask no futher question we'll return a leaf\n",
    "            \n",
    "            if gain == 0: \n",
    "                return Leaf(rows)\n",
    "            \n",
    "            # if we reach here, we have found a useful feature/ value to partition on\n",
    "            \n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "            \n",
    "            # recursively build the true branch\n",
    "            true_branch = build_tree(true_rows)\n",
    "            \n",
    "            # recursively build the false branch\n",
    "            false_branch = build_tree(false_rows)\n",
    "            \n",
    "            # return a question node. \n",
    "            # this records the best feature/value to ask at this point,\n",
    "            # as well as the branches to follow\n",
    "            # depending on the answer\n",
    "            \n",
    "            return Decision_Node(question,true_branch,false_branch)\n",
    "        def print_tree (node , spacing=\"\"):\n",
    "            \"\"\"Worlds most elegant tree printing function\"\"\"\n",
    "            \n",
    "            # Base case: we've reached a leaf\n",
    "            if isinstance(node, Leaf):\n",
    "                print(spacing + 'predict', node.predictions)\n",
    "                return\n",
    "            \n",
    "            # print the question at this node\n",
    "            print(spacing + str(node.question))\n",
    "            \n",
    "            # call this function recursively on the true branch\n",
    "            print(spacing + '--> True:')\n",
    "            print_tree(node.true_branch, spacing+\" \")\n",
    "            \n",
    "            # call this function recursiverly on the false branch\n",
    "            print(spacing + '--> False:')\n",
    "            print_tree(node.false_branch, spacing+\" \")\n",
    "            \n",
    "        def classify(row, node):\n",
    "            \n",
    "            # Base case: we've reached a leaf\n",
    "            if isinstance(node,leaf):\n",
    "                return node.predictions\n",
    "            \n",
    "            # decide whether to follow the true-branch of false-branch\n",
    "            # compare the feature /value stored in the node to the example we're considering\n",
    "            if node.question.match(row):\n",
    "                return classify(row, node.true_branch)\n",
    "            else:\n",
    "                return classify(row, node.false_branch)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "     \n",
    "    \n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This car has a color of  yellow and the milage is 1233"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __str__ easy to read for human consumption\n",
    "# __repr__ to be un ambigious as possible to class objects\n",
    "\n",
    "class car:\n",
    "    def __init__(self,milage,color):\n",
    "        self.milage = milage\n",
    "        self.color = color\n",
    "    def __repr__(self):\n",
    "        return 'This car has a color of  {self.color} and the milage is {self.milage}'.format(self = self)\n",
    "    \n",
    "cars = car(1233,'yellow')\n",
    "cars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
